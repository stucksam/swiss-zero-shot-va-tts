#!/bin/bash
#SBATCH --time=1440
#SBATCH --job-name=run_tts_chde_stucksam
#SBATCH --ntasks=1
#SBATCH --nodes=1
#SBATCH --gres=gpu:1
#SBATCH --mem=64G
#SBATCH --account=cai_nlp
#SBATCH --partition=p_gpu_high_end
#SBATCH --output=/cluster/home/stucksam/log/%j_%N__run_segment_stucksam.out
#SBATCH --error=/cluster/home/stucksam/log/%j_%N__run_segment_stucksam.err

# %j: parses the slurm jobID into the file-name
# %N: parses the Node name into the file-name

env_name="ma"
venv_base_dir="/raid/persistent_scratch/stucksam/venvs"
venv_path="$venv_base_dir/$env_name"

# create venv base dir if it does not exist
mkdir -p /raid/persistent_scratch/stucksam/venvs/

# Explicitly load cuda 12.2.2
module load cuda/12.2.2

# Check if the virtual environment exists
echo "Searching ($venv_path)..."
if [ -d "$venv_path" ]; then
    echo "Virtual environment ($env_name) found. Activating..."
    source "$venv_path/bin/activate"
else
    echo "Virtual environment ($env_name) not found. Creating..."
    module load python/3.11.9
    virtualenv $venv_path
    unset PIP_TARGET
    unset PYTHONPATH
    source "$venv_path/bin/activate"
    pip3 install -r requirements.txt
fi
# Source and destination directories
NAME="Tagesgespr√§ch"
FILENAME="$NAME.tar"
SOURCE_DIR="/cluster/home/stucksam/datasets/$FILENAME"
DEST_DIR="/scratch/stucksam"

mkdir -p $DEST_DIR/$NAME

echo "$DEST_DIR/$NAME.hdf5"

cp -r "$SOURCE_DIR" "$DEST_DIR/"
tar -xvf $DEST_DIR/$FILENAME -C DEST_DIR/$NAME
ls -latr $DEST_DIR

echo "Finished copying"

# see https://github.com/pytorch/pytorch/issues/111469
#export LD_LIBRARY_PATH=$venv_path/lib64/python3.11/site-packages/nvidia/nvjitlink/lib:$LD_LIBRARY_PATH
python3 main.py -p "$NAME"
ls -latr $DEST_DIR

mv "$DEST_DIR/$NAME.hdf5" "/cluster/home/stucksam/datasets/"
mv "$DEST_DIR/$NAME.txt" "/cluster/home/stucksam/datasets/"

# submit the job:
# sbatch <path-to-submit-file>/main.submit

